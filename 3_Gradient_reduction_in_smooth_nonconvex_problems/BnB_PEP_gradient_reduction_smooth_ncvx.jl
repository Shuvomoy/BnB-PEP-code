
# using Weave
# cd("directory that contains the .jmd file") # directory that contains the .jmd file
# tangle("file_name.jmd", informat = "markdown")


## Comment about the notation in the code
# ---------------------------------------
# Every notation in the paper are kept the same in the code, except:
# (i) the subscript â‹† (e.g., x_â‹†) in the paper corresponds to index `-1` (e.g, `x[-1]`) in the code
# (ii) the stepsize Ì„h $\bar{h}$ in the paper corresponds to $\alpha$ in the code

## Load the packages:
# ------------------
using JuMP, MosekTools, Mosek, LinearAlgebra,  OffsetArrays,  Gurobi, Ipopt, JLD2, Distributions, KNITRO, OrderedCollections, BenchmarkTools

## Load the pivoted Cholesky finder
# ---------------------------------
include("code_to_compute_pivoted_cholesky.jl")

## If using Pardiso solver for solving linear system, please uncomment the following code:
# If using Pardiso,

# using Libdl

# Libdl.dlopen("/usr/lib/x86_64-linux-gnu/liblapack.so.3", RTLD_GLOBAL)

# Libdl.dlopen("/home/gridsan/sdgupta/sdgupta_lib/usr/lib/x86_64-linux-gnu/libomp.so.5", RTLD_GLOBAL)

# Please use appropriate directory location for your version liblapack.so.3 and libomp.so.5


## Some helper functions

# construct e_i in R^n
function e_i(n, i)
    e_i_vec = zeros(n, 1)
    e_i_vec[i] = 1
    return e_i_vec
end

# this symmetric outer product is used when a is constant, b is a JuMP variable
function âŠ™(a,b)
    return ((a*b') .+ transpose(a*b')) ./ 2
end

# this symmetric outer product is for computing âŠ™(a,a) where a is a JuMP variable
function âŠ™(a)
    return a*transpose(a)
end

# function to compute cardinality of a vector
function compute_cardinality(x, Ïµ_sparsity)
    n = length(x)
    card_x = 0
    for i in 1:n
        if abs(x[i]) >=  Ïµ_sparsity
            card_x = card_x + 1
        end
    end
    return card_x
end

# function to compute rank of a matrix
function compute_rank(X, Ïµ_sparsity)
    eigval_array_X = eigvals(X)
    rnk_X = 0
    n = length(eigval_array_X)
    for i in 1:n
        if abs(eigval_array_X[i]) >= Ïµ_sparsity
            rnk_X = rnk_X + 1
        end
    end
    return rnk_X
end


## Step size conversion functions
# -------------------------------

function compute_Î±_from_h(h, N, L)
    Î± = OffsetArray(zeros(N, N), 1:N, 0:N-1)
    for â„“ in 1:N
        for i in 0:â„“-1
            if i==â„“-1
                Î±[â„“,i] = h[â„“,â„“-1]
            elseif i <= â„“-2
                Î±[â„“,i] = Î±[â„“-1,i] + h[â„“,i]
            end
        end
    end
    return Î±
end

function compute_h_from_Î±(Î±, N, L)
    h_new = OffsetArray(zeros(N, N), 1:N, 0:N-1)
    for l in N:-1:1
        h_new[l,l-1] = Î±[l,l-1]
        for i in l-2:-1:0
            h_new[l,i] = Î±[l,i] - Î±[l-1,i]
        end
    end
    return h_new
end


# Options for these function are
# step_size_type = :Default => will create a last step of 1/(L) rest will be zero
# step_size_type = :Random => will create a random stepsize

function feasible_h_Î±_generator(N, L; step_size_type = :Default)

    # construct h
    # -----------
    h = OffsetArray(zeros(N, N), 1:N, 0:N-1)
    if step_size_type == :Default
        for i in 1:N
            h[i, i-1] =  1 # because we have defined h[i,i-1]/L in the algorithm, so declaring 1 will make the stepsizes equal to 1/L
            # this is the optimal stepsize in (0,1/L] due to https://arxiv.org/pdf/2104.05468.pdf
        end
    elseif step_size_type == :Random
        for i in 1:N
            h[i,i-1] = Uniform(0, 1)
        end
    end

    # find Î± from h
    # -------------

    Î± = compute_Î±_from_h(h, N, L)

    return h, Î±

end


## Data generator function
# ------------------------

# Option for this function:
# input_type == :stepsize_constant means we know the stepsize
# input_type == :stepsize_variable means the stepsize is a decision variable

function data_generator_function(N, Î±, L; input_type = :stepsize_constant)

    dim_ğ± = N+2
    dim_ğ  = N+2
    dim_ğŸ = N+1
    N_pts = N+2 # number of points corresponding to [x_â‹†=x_{-1} x_0 ... x_N]

    ğ±_0 = e_i(dim_ğ±, 1)

    ğ±_star = zeros(dim_ğ±, 1)

    # initialize ğ  and ğŸ vectors

    # ğ  = [ğ _{-1}=ğ _â‹† âˆ£ ğ _0 âˆ£ ğ _1 âˆ£... âˆ£ ğ _N]

    ğ  =  OffsetArray(zeros(dim_ğ , N_pts), 1:dim_ğ , -1:N)

    # ğŸ  = [ğŸ_{-1}=ğŸ_â‹† âˆ£ ğŸ_0 âˆ£ ğŸ_1 âˆ£... âˆ£ ğŸ_N]

    ğŸ = OffsetArray(zeros(dim_ğŸ, N_pts), 1:dim_ğŸ, -1:N)

    # construct ğ  vectors, note that ğ _â‹†  is already constructed zero

    for k in 0:N
        ğ [:,k] = e_i(dim_ğ , k+2)
    end

    # construct ğŸ vectors, note that ğŸ_â‹† is already constructed zero

    for k in 0:N
        ğŸ[:,k] = e_i(dim_ğŸ, k+1)
    end

    # time to define the ğ± vectors, which requires more care

    if input_type == :stepsize_constant

        # ğ± = [ğ±_{â‹†} = ğ±{-1} âˆ£ ğ±_0 âˆ£ ğ±_1 âˆ£ ... âˆ£ ğ±_N]

        ğ± = OffsetArray(zeros(dim_ğ±, N_pts), 1:dim_ğ±, -1:N)

        # define ğ±_0 which corresponds to x_0

        ğ±[:,0] = ğ±_0

        # construct part of ğ± corresponding to the x iterates: x_1, ..., x_N

        for i in 1:N
            ğ±[:,i] = ğ±_0  - ( (1/L)*sum( Î±[i,j] * ğ [:,j] for j in 0:i-1) )
        end

    elseif input_type == :stepsize_variable

        # caution ğŸ’€: keep in mind that this matrix ğ± is not 0 indexed yet, so while constructing its elements, ensure to use the full formula for ğ±_i

        ğ± = [ğ±_star ğ±_0]

        # construct part of ğ± corresponding to the x iterates: x_1, ..., x_N

        for i in 1:N
            ğ±_i = ğ±_0  - ( (1/L)*sum( Î±[i,j] * ğ [:,j] for j in 0:i-1) )
            ğ± = [ğ± ğ±_i]
        end

        # make ğ± an offset array to make our life comfortable

        ğ± = OffsetArray(ğ±, 1:dim_ğ±, -1:N)
    end

    # time to return

    return ğ±, ğ , ğŸ

end


# Index set creator function for the dual variables Î», Ï„, Î·

struct i_j_idx # correspond to (i,j) pair, where i,j âˆˆ I_N_â‹†
    i::Int64 # corresponds to index i
    j::Int64 # corresponds to index j
end

struct i_idx # correspond i in some set
    i::Int64
end

# We have 3 dual variables that operate over mulitple index sets
# Î»_ij where i,j âˆˆ I_N_star,
# Î·_i  where i âˆˆ [0:N],
# Ï„_i where i  âˆˆ I_N_star,
# so we write a function to construct these index sets

function index_set_constructor_for_dual_vars_full(N)

    I_N_star = -1:N

    # construct the index set for Î»
    idx_set_Î» = i_j_idx[]
    for i in I_N_star
        for j in I_N_star
            if i!=j
                push!(idx_set_Î», i_j_idx(i,j))
            end
        end
    end

    # construct the index set for Î· and Ï„, both of which would have the same index set for the full case

    idx_set_Ï„ = i_idx[]
    for i in 0:N #I_N_star
        push!(idx_set_Ï„, i_idx(i))
    end

    idx_set_Î· = i_idx[]
    for i in 0:N
        push!(idx_set_Î·, i_idx(i))
    end

    return idx_set_Î», idx_set_Ï„, idx_set_Î·

end

function effective_index_set_finder(Î», Ï„, Î·; Ïµ_tol = 0.0005)

    # the variables Î», Ï„, Î· are of the type DenseAxisArray whose index set can be accessed using _.axes and data via _.data syntax

    idx_set_Î»_current = (Î».axes)[1]

    idx_set_Ï„_current = (Ï„.axes)[1]

    idx_set_Î·_current = (Î·.axes)[1]

    idx_set_Î»_effective = i_j_idx[]

    idx_set_Ï„_effective = i_idx[]

    idx_set_Î·_effective = i_idx[]

    # construct idx_set_Î»_effective

    for i_j_Î» in idx_set_Î»_current
        if abs(Î»[i_j_Î»]) >= Ïµ_tol # if Î»[i,j] >= Ïµ, where Ïµ is our cut off for accepting nonzero
            push!(idx_set_Î»_effective, i_j_Î»)
        end
    end

    # construct idx_set_Ï„_effective

    for i_Ï„ in idx_set_Ï„_current
        if abs(Ï„[i_Ï„]) >= Ïµ_tol
            push!(idx_set_Ï„_effective, i_Ï„)
        end
    end

    # construct idx_set_Î·_effective

    for i_Î· in idx_set_Î·_current
        if abs(Î·[i_Î·]) >= Ïµ_tol
            push!(idx_set_Î·_effective, i_Î·)
        end
    end

    return idx_set_Î»_effective, idx_set_Ï„_effective, idx_set_Î·_effective

end

# The following function will return the zero index set of a known L_cholesky i.e., those indices of  that are  L  that are zero. ğŸ’€ Note that for Î» we are doing the opposite.

function zero_index_set_finder_L_cholesky(L_cholesky; Ïµ_tol = 1e-4)
    n_L_cholesky, _ = size(L_cholesky)
    zero_idx_set_L_cholesky = []
    for i in 1:n_L_cholesky
        for j in 1:n_L_cholesky
            if i >= j # because i<j has L_cholesky[i,j] == 0 for lower-triangual structure
                if abs(L_cholesky[i,j]) <= Ïµ_tol
                    push!(zero_idx_set_L_cholesky, (i,j))
                end
            end
        end
    end
    return zero_idx_set_L_cholesky
end


function index_set_zero_entries_dual_variables(N, idx_set_Î», idx_set_Ï„, idx_set_Î·)

    idx_set_zero_Î· = []

    # zero index set of Î»: by solving the BnB-PEPs for N=1,â€¦,5, we have found the pattern that Î»[*,k]=0 and Î»[k,*]=0

    idx_set_zero_Î»_init = []

    for k in 0:N
        idx_set_zero_Î»_init = [idx_set_zero_Î»_init; i_j_idx(-1,k)]
    end

    for k in 0:N
        idx_set_zero_Î»_init = [idx_set_zero_Î»_init; i_j_idx(k, -1)]
    end

    idx_set_zero_Î» = intersect(idx_set_zero_Î»_init, idx_set_Î»)


    # we have found the pattern Ï„[0]=â€¦=Ï„[N-1] to be true by solving the BnB-PEPs for N=1,â€¦,5

    idx_set_nz_Ï„ = []
    idx_set_nz_Ï„ = [idx_set_nz_Ï„ ; i_idx(N)]

    idx_set_zero_Ï„ = setdiff(idx_set_Ï„, idx_set_nz_Ï„)

    return idx_set_zero_Î», idx_set_zero_Ï„, idx_set_zero_Î·

end


A_tilde_mat(i,j,Î±,ğ ,ğ±) = âŠ™(ğ [:,i]+ğ [:,j], ğ±[:,i]-ğ±[:,j])
B_mat(i,j,Î±,ğ±) = âŠ™(ğ±[:,i]-ğ±[:,j], ğ±[:,i]-ğ±[:,j])
C_mat(i,j,ğ ) = âŠ™(ğ [:,i]-ğ [:,j], ğ [:,i]-ğ [:,j])
a_vec(i,j,ğŸ) = ğŸ[:, j] - ğŸ[:, i]


function solve_primal_with_known_stepsizes(N, R, L, Î±; show_output = :off)

    # generate the bold vectors
    # -------------------------

    ğ±, ğ , ğŸ = data_generator_function(N, Î±, L; input_type = :stepsize_constant)

     # declare the model
    # -----------------
    model_primal_PEP_with_known_stepsizes = Model(optimizer_with_attributes(Mosek.Optimizer))

    # dimension of the decision variables G and Ft
    # --------------------------------------------
    I_N_star = -1:N
    dim_G = N+2
    dim_Ft = N+1

    # add the variables
    # -----------------
    @variable(model_primal_PEP_with_known_stepsizes, G[1:dim_G, 1:dim_G], PSD)

    @variable(model_primal_PEP_with_known_stepsizes, Ft[1:dim_Ft]) # For modeling advantage we have defined a column vector Ft = F^T which is transpose of the row matrix F in our model

    @variable(model_primal_PEP_with_known_stepsizes, t)

    # define objective
    # ----------------

    @objective(model_primal_PEP_with_known_stepsizes, Max, t)

     # define the constraints
    # ----------------------

    # hypograph constraint

    for i in 0:N
        @constraint(model_primal_PEP_with_known_stepsizes, t <= tr(G*C_mat(i,-1,ğ )) )
    end

    # interpolation constraint

    for i in I_N_star
        for j in I_N_star
            if i != j
                @constraint(model_primal_PEP_with_known_stepsizes, Ft'*a_vec(i,j,ğŸ) - ((L/4)*tr(G*B_mat(i,j,Î±,ğ±))) + (0.5*tr(G*A_tilde_mat(i,j,Î±,ğ ,ğ±))) + ( (1/(4*L))*tr(G*C_mat(i,j,ğ )) ) <= 0 )
            end
        end
    end

    # lower bound condition

    for i in I_N_star
        @constraint(model_primal_PEP_with_known_stepsizes, Ft'*a_vec(i,-1,ğŸ) + ((1/(2*L))*tr(G*C_mat(i,-1,ğ ))) <= 0)
    end


    # initial condition

    @constraint(model_primal_PEP_with_known_stepsizes, Ft'*a_vec(-1,0,ğŸ)  <= R^2)

    # @constraint(model_primal_PEP_with_known_stepsizes, Ft'*a_vec(N,0,ğŸ) <= R^2)

    # time to optimize
    # ----------------
    set_silent(model_primal_PEP_with_known_stepsizes)

    optimize!(model_primal_PEP_with_known_stepsizes)

    if termination_status(model_primal_PEP_with_known_stepsizes) != MOI.OPTIMAL
        @warn "primal PEP with known stepsizes did not reach optimality; termination status = " termination_status(model_primal_PEP_with_known_stepsizes)
    end

    p_star = objective_value(model_primal_PEP_with_known_stepsizes)

    # @show "p_star = $p_star"

    G_star = value.(G)

    Ft_star = value.(Ft)

    return p_star, G_star, Ft_star

end


# N = 3
# R = 1
# L = 1
# h_feas, Î±_feas = feasible_h_Î±_generator(N, L; step_size_type = :Default)
# p_feas, G_feas, Ft_feas = solve_primal_with_known_stepsizes(N, R, L, Î±_feas; show_output = :off)


# In this function, the most important option is objective type:
# 0) :default will minimize Î½*R^2 (this is the dual of the primal pep for a given stepsize)
# other options are
# 1) :find_sparse_sol, this will find a sparse solution given a particular stepsize and objective value upper bound
# 2) :find_M_Î» , find the upper bound for the Î» variables by maximizing ||Î»||_1 for a given stepsize and particular objective value upper bound
# 3) :find_M_Ï„, find the upper bound for the Ï„ variables by maximizing || Ï„ ||_1
# 4) :find_M_Î·, find the upper bound for the Î· variables by maximizing ||Î·||_1
# 5) :find_M_Z, find the upper bound for the entries of the slack matrix Z, by maximizing tr(Z) for for a given stepsize and particular objective value upper bound

function solve_dual_PEP_with_known_stepsizes(N, R, L, Î±;
    show_output = :off,
    Ïµ_tol_feas = 1e-6,
    objective_type = :default,
    obj_val_upper_bound = default_obj_val_upper_bound)

    # generate bold vectors
    # ---------------------

     ğ±, ğ , ğŸ = data_generator_function(N, Î±, L; input_type = :stepsize_constant)

    # index set of points
    # -------------------

    I_N_star = -1:N
    dim_Z = N+2
    dim_ğ± = N+2

    # define the model
    # ---------------
    # model_dual_PEP_with_known_stepsizes = Model(optimizer_with_attributes(Mosek.Optimizer, "MSK_DPAR_INTPNT_CO_TOL_PFEAS" => 1e-10))

    model_dual_PEP_with_known_stepsizes = Model(optimizer_with_attributes(Mosek.Optimizer))

    # define the index set for the dual variables
    # -------------------------------------------
    idx_set_Î», idx_set_Ï„, idx_set_Î· = index_set_constructor_for_dual_vars_full(N)

    # define Î»
    # --------
    @variable(model_dual_PEP_with_known_stepsizes, Î»[idx_set_Î»] >= 0)

    # define Ï„ (the variable corresponding to lower bound)
    # -------
    @variable(model_dual_PEP_with_known_stepsizes, Ï„[idx_set_Ï„] >= 0)

    # define Î·
    # --------
    @variable(model_dual_PEP_with_known_stepsizes, Î·[idx_set_Î·] >= 0)

    # define Î½
    # --------
    @variable(model_dual_PEP_with_known_stepsizes, Î½ >= 0)

    # define Z âª° 0
    # ------------

    @variable(model_dual_PEP_with_known_stepsizes, Z[1:dim_Z, 1:dim_Z], PSD)

    # add objective
    # -------------
    if objective_type == :default

        @info "ğŸ’ Minimizing the usual performance measure"

        @objective(model_dual_PEP_with_known_stepsizes, Min,  Î½*R^2)

    elseif objective_type == :find_sparse_sol

        @info "ğŸ® Finding a sparse dual solution given the objective value upper bound"

        # @objective(model_dual_PEP_with_known_stepsizes, Min, sum(Î·[i] for i in idx_set_Î·) + sum(Ï„[i] for i in idx_set_Ï„) + sum(Î»[i_j] for i_j in idx_set_Î») )

        @objective(model_dual_PEP_with_known_stepsizes, Min, sum(Î·[i] for i in idx_set_Î·) + sum(Ï„[i] for i in idx_set_Ï„) + sum(Î»[i_j] for i_j in idx_set_Î») )

        @constraint(model_dual_PEP_with_known_stepsizes, Î½*R^2 <= obj_val_upper_bound)

    elseif objective_type == :find_M_Î»

        @info "[ğŸ· ] Finding upper bound on the entries of Î» for BnB-PEP"

        @objective(model_dual_PEP_with_known_stepsizes, Max, sum(Î»[i_j] for i_j in idx_set_Î»))

        @constraint(model_dual_PEP_with_known_stepsizes,  Î½*R^2 <= obj_val_upper_bound)

    elseif objective_type == :find_M_Ï„

        @info "[ğŸ· ] Finding upper bound on the entries of Ï„ for BnB-PEP"

        @objective(model_dual_PEP_with_known_stepsizes, Max, sum(Ï„[i] for i in idx_set_Ï„))

        @constraint(model_dual_PEP_with_known_stepsizes,  Î½*R^2 <= obj_val_upper_bound)


    elseif objective_type == :find_M_Î·

        @info "[ğŸ· ] Finding upper bound on the entries of Î· for BnB-PEP"

        @objective(model_dual_PEP_with_known_stepsizes, Max, sum(Î·[i] for i in idx_set_Î·))

        @constraint(model_dual_PEP_with_known_stepsizes,  Î½*R^2 <= obj_val_upper_bound)

    elseif objective_type == :find_M_Z

        @objective(model_dual_PEP_with_known_stepsizes, Max, tr(Z))

        @constraint(model_dual_PEP_with_known_stepsizes,  Î½*R^2 <= obj_val_upper_bound)

    else

        @error "something is not right in objective type option setting"

    end

    # add linear constraint
    # ---------------------
    @constraint(model_dual_PEP_with_known_stepsizes,
    ( sum(Î»[i_j_Î»] * a_vec(i_j_Î».i, i_j_Î».j, ğŸ) for i_j_Î» in idx_set_Î») +
    sum(Ï„[i_Ï„] * a_vec(i_Ï„.i,-1,ğŸ) for i_Ï„ in idx_set_Ï„) +
    Î½*a_vec(-1,0,ğŸ)
    )
    .== 0
    )

    # add LMI constraint
    # ----------------------------------------------

    @constraint(model_dual_PEP_with_known_stepsizes,
    ( -sum(Î·[i_Î·]*C_mat(i_Î·.i,-1,ğ ) for i_Î· in idx_set_Î·) )+
    ( (1/(2*L))*sum(Ï„[i_Ï„]*C_mat(i_Ï„.i,-1,ğ ) for i_Ï„ in idx_set_Ï„) ) +
    (
    sum(Î»[i_j_Î»]*(
    ( (-L/4)*B_mat(i_j_Î».i, i_j_Î».j, Î±, ğ±) ) +
    ( (0.5)*A_tilde_mat(i_j_Î».i, i_j_Î».j, Î±, ğ , ğ±) ) +
    ( (1/(4*L))*C_mat(i_j_Î».i,i_j_Î».j,ğ ) )
    ) for i_j_Î» in idx_set_Î»)
    )
    .==
    Z
    )


    # add sum(Î·) == 1 constraint

    @constraint(model_dual_PEP_with_known_stepsizes, sum(Î·[i_Î·] for i_Î· in idx_set_Î·) .== 1)

    # time to optimize
    # ----------------

    if show_output == :off
        set_silent(model_dual_PEP_with_known_stepsizes)
    end

    optimize!(model_dual_PEP_with_known_stepsizes)

    if termination_status(model_dual_PEP_with_known_stepsizes) != MOI.OPTIMAL
        @info "model_dual_PEP_with_known_stepsizes solving did not reach optimality;  termination status = " termination_status(model_dual_PEP_with_known_stepsizes)
    end

    # store the solutions and return
    # ------------------------------

    # store Î»_opt

    Î»_opt = value.(Î»)

    # store Î·_opt

    Î·_opt = value.(Î·)

    # store Ï„_opt

    Ï„_opt = value.(Ï„)

    # store Î½_opt

    Î½_opt = value(Î½)

    # store Z_opt

    Z_opt = value.(Z)

    # compute cholesky

    L_cholesky_opt =  compute_pivoted_cholesky_L_mat(Z_opt)

    if norm(Z_opt - L_cholesky_opt*L_cholesky_opt', Inf) > 1e-6
        @info "checking the norm bound"
        @warn "||Z - L*L^T|| = $(norm(Z_opt - L_cholesky_opt*L_cholesky_opt', Inf))"
    end

    # compute {Î˜[i,j]}_{i,j} where i,jâˆˆI_N_â‹†
    Î˜_opt = zeros(dim_ğ±, dim_ğ±, length(idx_set_Î»))

    for â„“ in 1:length(idx_set_Î»)
        i_j_Î» = idx_set_Î»[â„“]
        Î˜_opt[:,:,â„“] = âŠ™(ğ±[:,i_j_Î».i]-ğ±[:,i_j_Î».j], ğ±[:,i_j_Î».i]-ğ±[:,i_j_Î».j])
        if norm(Î˜_opt[:,:,â„“] - B_mat(i_j_Î».i, i_j_Î».j, Î±, ğ±), Inf) > 1e-6
            @error "something is not right in Î˜"
            return
        end
    end

    # store objective

    # obj_val = objective_value(model_dual_PEP_with_known_stepsizes)

    # effective index sets for the dual variables Î», Ï„, Î·

    idx_set_Î»_effective, idx_set_Ï„_effective, idx_set_Î·_effective = effective_index_set_finder(Î»_opt, Ï„_opt, Î·_opt; Ïµ_tol = 0.0005)

    # return all the stored values

    # store objective and other goodies

    â„“_1_norm_Î» = sum(Î»_opt)

    â„“_1_norm_Î· = sum(Î·_opt)

    â„“_1_norm_Ï„ = sum(Ï„_opt)

    tr_Z = tr(Z_opt)

    original_performance_measure = Î½_opt*R^2

    return original_performance_measure, â„“_1_norm_Î», â„“_1_norm_Ï„, â„“_1_norm_Î·, tr_Z, Î»_opt, Ï„_opt, Î·_opt, Î½_opt, Z_opt, L_cholesky_opt, Î˜_opt, Î±, idx_set_Î»_effective, idx_set_Ï„_effective, idx_set_Î·_effective

end


# # will test the primal at the same time
# N = 5
# R = 1
# L = 1
# default_obj_val_upper_bound = 1e6
# h_feas, Î±_feas = feasible_h_Î±_generator(N, L; step_size_type = :Default)
#
# p_feas, G_feas, Ft_feas = solve_primal_with_known_stepsizes(N, R, L, Î±_feas; show_output = :off)
#
# original_performance_measure_feas, â„“_1_norm_Î»_feas, â„“_1_norm_Ï„_feas, â„“_1_norm_Î·_feas, tr_Z_feas, Î»_feas, Ï„_feas, Î·_feas, Î½_feas, Z_feas, L_cholesky_feas, Î˜_feas, Î±_feas, idx_set_Î»_feas_effective, idx_set_Ï„_feas_effective, idx_set_Î·_feas_effective = solve_dual_PEP_with_known_stepsizes(N, R, L, Î±_feas;
#     show_output = :off,
#     Ïµ_tol_feas = 1e-6,
#     objective_type = :default,
#     obj_val_upper_bound = default_obj_val_upper_bound)
#
# @info "performance measure =$(p_feas)"
#
# @info "primal-dual gap = $(p_feas-original_performance_measure_feas)"



# We also provide a function to check if in a particular feasible solution, these bounds are violated

function bound_violation_checker_BnB_PEP(
    # input point
    # -----------
    d_star_sol, Î»_sol, Ï„_sol, Î·_sol, Î½_sol, Z_sol, L_cholesky_sol, Î˜_sol,  Î±_sol,
    # input bounds
    # ------------
    Î»_lb, Î»_ub, Ï„_lb, Ï„_ub, Î·_lb, Î·_ub, Î½_lb, Î½_ub, Z_lb, Z_ub, L_cholesky_lb, L_cholesky_ub, Î˜_lb, Î˜_ub, Î±_lb, Î±_ub;
    # options
    # -------
    show_output = :on,
    computing_global_lower_bound = :off
    )

    if show_output == :on
        @show [minimum(Î»_sol)  maximum(Î»_sol)  Î»_ub]
        @show [minimum(Ï„_sol)  maximum(Ï„_sol)  Ï„_ub]
        @show [minimum(Î·_sol)  maximum(Î·_sol)  Î·_ub]
        @show [Î½_lb Î½_sol Î½_ub]
        @show [Z_lb minimum(Z_sol)   maximum(Z_sol)  Z_ub]
        @show [L_cholesky_lb  minimum(L_cholesky_sol)  maximum(L_cholesky_sol) L_cholesky_ub]
        @show [Î±_lb minimum(Î±_sol) maximum(Î±_sol) Î±_ub]
        @show [Î˜_lb minimum(Î˜_sol) maximum(Î˜_sol) Î˜_ub]
    end

    # bound satisfaction flag

    bound_satisfaction_flag = 1

    # verify bound for Î»
    if !(maximum(Î»_sol) < Î»_ub + 1e-8) # lower bound is already encoded in the problem constraint
        @error "found Î» is violating the input bound"
        bound_satisfaction_flag = 0
    end

    # verify bound for Ï„
    if !(maximum(Ï„_sol) < Ï„_ub + 1e-8) # lower bound is already encoded in the problem constraint
        @error "found Ï„ is violating the input bound"
        bound_satisfaction_flag = 0
    end

    # verify bound for Î·
    if !(maximum(Î·_sol) < Î·_ub + 1e-8) # lower bound is already encoded in the problem constraint
        @error "found Î· is violating the input bound"
        bound_satisfaction_flag = 0
    end

    # verify bound for Î½: this is not necessary because this will be ensured due to our objective function being Î½ R^2
    # if !(maximum(Î½_sol) <= Î½_ub) # lower bound is already encoded in the problem constraint
    #     @error "found Î½ is violating the input bound"
    #     bound_satisfaction_flag = 0
    # end

    # verify bound for Z
    if !(Z_lb -  1e-8 < minimum(Z_sol) && maximum(Z_sol) < Z_ub + 1e-8)
        @error "found Z is violating the input bound"
        bound_satisfaction_flag = 0
    end

    # verify bound for Î˜
    if !(Î˜_lb -  1e-8 < minimum(Î˜_sol) && maximum(Î˜_sol) < Î˜_ub + 1e-8)
        @error "found Z is violating the input bound"
        bound_satisfaction_flag = 0
    end

    # verify bound for L_cholesky
    if computing_global_lower_bound == :off
        if !(L_cholesky_lb -  1e-8 < minimum(L_cholesky_sol) && maximum(L_cholesky_sol) < L_cholesky_ub +  1e-8)
            @error "found L_cholesky is violating the input bound"
            bound_satisfaction_flag = 0
        end
    elseif computing_global_lower_bound == :on
        @info "no need to check bound on L_cholesky"
    end

    # verify bound for Î±
    if !(Î±_lb -  1e-8 < minimum(Î±_sol) && maximum(Î±_sol) < Î±_ub + 1e-8)
        @error "found Î± is violating the input bound"
        bound_satisfaction_flag = 0
    end

    # # verify bound for objective value: this is not necessary again, this is already done in BnB_PEP_solver
    # if abs(obj_val_sol-BnB_PEP_cost_lb) <= Ïµ_tol_sol
    #     @error "found objective value is violating the input bound"
    #     bound_satisfaction_flag = 0
    # end

    if bound_satisfaction_flag == 0
        @error "[ğŸ’€ ] some bound is violated, increase the bound intervals"
    elseif bound_satisfaction_flag == 1
        @info "[ğŸ˜… ] all bounds are satisfied by the input point, rejoice"
    end

    return bound_satisfaction_flag

end


function BnB_PEP_solver(
    # different parameters to be used
    # ------------------------------
    N, L, R,
    # solution to warm-start (Î˜ is warm-started internally)
    # -----------------------------------------------------
    d_star_ws, Î»_ws, Ï„_ws, Î·_ws, Î½_ws, Z_ws, L_cholesky_ws, Î±_ws, idx_set_Î»_ws_effective, idx_set_Ï„_ws_effective, idx_set_Î·_ws_effective,
    # bounds on the variables (M_Î˜ is computed internally)
    # ----------------------------------------------------
    M_Î», M_Ï„, M_Î·, M_Î±, M_Z, M_L_cholesky, M_Î½;
    # options
    # -------
    solution_type = :find_locally_optimal, # other option :find_globally_optimal
    show_output = :off, # other option :on
    local_solver = :ipopt, # other option :knitro
    knitro_multistart = :off, # other option :on (only if :knitro solver is used)
    knitro_multi_algorithm = :off, # other option on (only if :knitro solver is used)
    reduce_index_set_for_dual_variables = :for_warm_start_only,
    # options for reduce_index_set_for_dual_variables
    # (i) :on (making it :on will make force a dual variable 0, if the corresponding index lies int idx_set_variable_ws),
    # (ii) :off , this will define the dual variables and warm-start over the full index set (not recommended)
    # (iii) :for_warm_start_only , this option is the same as the :off option, however in this case we will define dual variables over the full index set, but warm-start from a dual_variable that has reduced index set (recommended)
    reduce_index_set_for_L_cholesky = :off, # the other option is :on
    positive_step_size = :off, # other option is :on (i.e., making it :on will enforce the stepsize to be non-negative, which will turn BnB-PEP solver into a heuristic), ğŸ’€ turning it :on is not recommended
    find_global_lower_bound_via_cholesky_lazy_constraint = :off, # if this on, then we model Z = L_cholesky*L_cholesky^T via lazy constraint (the goal is to find a lower bound to BnB PEP)
    bound_impose = :off, # if this is :on, then from the warm_start solution we compute lower and upper bounds for the decision variables using the semidefinite relaxation,
    quadratic_equality_modeling = :through_Ïµ, # other option is :exact
    #  quadratic_equality_modeling == :exact models a nonconvex quadratic constraint x^T P x + q^T x + r == 0 exactly in JuMP
    #  quadratic_equality_modeling == : :through_Ïµ models the constraint x^T P x + q^T x + r == 0 as two constraints:
    # x^T P x + q^T x + r <= Ïµ_tol_feas, and
    #  x^T P x + q^T x + r >= -Ïµ_tol_feas,
    # where Ïµ_tol_feas is our tolerance for feasibility. This is recommended while solving using Gurobi
    cholesky_modeling = :formula, # : formula impelements the equivalent representation of Z = L_cholesky*L_cholesky^T via formulas, the other option is :definition, that directly model Z = L_cholesky*L_cholesky^T
    Ïµ_tol_feas = 1e-6, # tolerance for feasibility
    Ïµ_tol_Cholesky = 0.0005, # tolerance for determining which elements of L_cholesky_ws is zero
    maxCutCount=1e3, # this is the number of cuts to be added if the lazy constraint callback is activated
    global_lower_bound_given = :off, # wheather is a global lower bound is given, providing this would make the branch-and-bound faster
    global_lower_bound = 0.0, # value of the global lower bound (if nothing is given then 0 is a valid lower bound)
    polish_solution = :on, # wheather to polish the solution to get better precision, the other option is :off,
    M_Î˜_factor = 100, # factor by which to magnify the internal M_Î˜,
    impose_pattern = :off # other option is :on,  if it is turned on then we impose the pattern found by solving BnB-PEP from solving N=1,2,3,â€¦,5
    )

    # Number of points
    # ----------------

    I_N_star = -1:N
    dim_Z = N+2
    dim_ğ± = N+2
    ğ±_0 = e_i(dim_ğ±, 1)
    ğ±_star = zeros(dim_ğ±, 1)

    # *************
    # declare model
    # -------------
    # *************

    if solution_type == :find_globally_optimal

        @info "[ğŸŒ ] globally optimal solution finder activated, solution method: spatial branch and bound"

        BnB_PEP_model =  Model(Gurobi.Optimizer)
        # using direct_model results in smaller memory allocation
        # we could also use
        # Model(Gurobi.Optimizer)
        # but this requires more memory

        set_optimizer_attribute(BnB_PEP_model, "NonConvex", 2)
        # "NonConvex" => 2 tells Gurobi to use its nonconvex algorithm

        set_optimizer_attribute(BnB_PEP_model, "MIPFocus", 3)
        # If you are more interested in good quality feasible solutions, you can select MIPFocus=1.
        # If you believe the solver is having no trouble finding the optimal solution, and wish to focus more
        # attention on proving optimality, select MIPFocus=2.
        # If the best objective bound is moving very slowly (or not at all), you may want to try MIPFocus=3 to focus on the bound.

        # ğŸ‘: other Gurobi options one can play with
        # ------------------------------------------

        # turn off all the heuristics
        # set_optimizer_attribute(BnB_PEP_model, "Heuristics", 0)
        # set_optimizer_attribute(BnB_PEP_model, "RINS", 0)

        # other termination epsilons for Gurobi
        # set_optimizer_attribute(BnB_PEP_model, "MIPGapAbs", 1e-4)

        set_optimizer_attribute(BnB_PEP_model, "MIPGap", 1e-2) # 99% optimal solution, because Gurobi will provide a result associated with a global lower bound within this tolerance, by polishing the result, we can find the exact optimal solution by solving a convex SDP

        # set_optimizer_attribute(BnB_PEP_model, "FuncPieceRatio", 0) # setting "FuncPieceRatio" to 0, will ensure that the piecewise linear approximation of the nonconvex constraints lies below the original function

        # set_optimizer_attribute(BnB_PEP_model, "Threads", 64) # how many threads to use at maximum
        #
        # set_optimizer_attribute(BnB_PEP_model, "FeasibilityTol", 1e-4)
        #
        # set_optimizer_attribute(BnB_PEP_model, "OptimalityTol", 1e-4)

    elseif solution_type == :find_locally_optimal

        @info "[ğŸ™ ] locally optimal solution finder activated, solution method: interior point method"

        if local_solver == :knitro

            @info "[ğŸš€ ] activating KNITRO"

            # BnB_PEP_model = Model(optimizer_with_attributes(KNITRO.Optimizer, "convex" => 0,  "strat_warm_start" => 1))

            BnB_PEP_model = Model(
                optimizer_with_attributes(
                KNITRO.Optimizer,
                "convex" => 0,
                "strat_warm_start" => 1,
                # the last settings below are for larger N
                # you can comment them out if preferred but not recommended
                "honorbnds" => 1,
                # "bar_feasmodetol" => 1e-3,
                "feastol" => 1e-7,
                # "infeastol" => 1e-12,
                "opttol" => 1e-7,
                # "maxit" => 100000
                )
            )

            if knitro_multistart == :on
                set_optimizer_attribute(BnB_PEP_model, "ms_enable", 1)
                set_optimizer_attribute(BnB_PEP_model, "par_numthreads", 8)
                set_optimizer_attribute(BnB_PEP_model, "par_msnumthreads", 8)
                # set_optimizer_attribute(BnB_PEP_model, "ms_maxsolves", 200)
            end

            if knitro_multi_algorithm == :on
                set_optimizer_attribute(BnB_PEP_model, "algorithm", 5)
                set_optimizer_attribute(BnB_PEP_model, "ma_terminate", 0)
            end

        elseif local_solver == :ipopt

            @info "[ğŸƒ ] activating IPOPT"

            BnB_PEP_model = Model(Ipopt.Optimizer)

            # very high precision solution in IPOPT can be obtained via the following code, comment them out if high precision is not required

            set_optimizer_attribute(BnB_PEP_model, "constr_viol_tol", 1e-6)

            set_optimizer_attribute(BnB_PEP_model, "dual_inf_tol", 1e-6)

            set_optimizer_attribute(BnB_PEP_model, "compl_inf_tol", 1e-6)

            set_optimizer_attribute(BnB_PEP_model, "tol", 1e-10)

            set_optimizer_attribute(BnB_PEP_model, "max_iter", 5000)

            # if using the Pardiso for solving linear system, please uncomment the following code:

            # set_optimizer_attribute(BnB_PEP_model, "linear_solver", "pardiso")

        end
    end

    # ************************
    # define all the variables
    # ------------------------
    # ************************

    @info "[ğŸ‰ ] defining the variables"

    # define Î», Ï„, Î·
    # --------------

    if reduce_index_set_for_dual_variables == :off
        # define Î»,  Ï„, Î· over the full index set
        idx_set_Î», idx_set_Ï„, idx_set_Î· = index_set_constructor_for_dual_vars_full(N)
        @variable(BnB_PEP_model, Î»[idx_set_Î»] >= 0)
        @variable(BnB_PEP_model, Ï„[idx_set_Ï„] >= 0)
        @variable(BnB_PEP_model, Î·[idx_set_Î·] >= 0)
    elseif reduce_index_set_for_dual_variables == :on
        # define Î» over a reduced index set, idx_set_Î»_ws_effective, which is the effective index set of Î»_ws
        idx_set_Î» = idx_set_Î»_ws_effective
        idx_set_Ï„ = idx_set_Ï„_ws_effective
        idx_set_Î· = idx_set_Î·_ws_effective
        @variable(BnB_PEP_model, Î»[idx_set_Î»] >= 0)
        @variable(BnB_PEP_model, Ï„[idx_set_Ï„] >= 0)
        @variable(BnB_PEP_model, Î·[idx_set_Î·] >= 0)
    elseif reduce_index_set_for_dual_variables == :for_warm_start_only
        # this :for_warm_start_only option is same as the :off option, however in this case we will define Î» over the full index set, but warm-start from a Î»_ws that has reduced index set
        idx_set_Î», idx_set_Ï„, idx_set_Î· = index_set_constructor_for_dual_vars_full(N)
        idx_set_Î»_ws = idx_set_Î»_ws_effective
        idx_set_Ï„_ws = idx_set_Ï„_ws_effective
        idx_set_Î·_ws = idx_set_Î·_ws_effective
        @variable(BnB_PEP_model, Î»[idx_set_Î»] >= 0)
        @variable(BnB_PEP_model, Ï„[idx_set_Ï„] >= 0)
        @variable(BnB_PEP_model, Î·[idx_set_Î·] >= 0)
    end

    # define Î½
    # --------

    @variable(BnB_PEP_model, Î½ >= 0)

    # define Z
    # --------

    @variable(BnB_PEP_model, Z[1:dim_Z, 1:dim_Z], Symmetric)

    if find_global_lower_bound_via_cholesky_lazy_constraint == :off

        # define the cholesky matrix of Z: L_cholesky
        # -------------------------------------------
        @variable(BnB_PEP_model, L_cholesky[1:dim_Z, 1:dim_Z])

    end

    # Define Î˜[i,j] matrices such that for i,j âˆˆ I_N_star, we have Î˜[i,j] = B_mat(i, j, Î±, ğ±) = âŠ™(ğ±[:,i] -ğ±[:,j], ğ±[:,i] - ğ±[:,j])

    Î˜ = BnB_PEP_model[:Î˜] = reshape(
    hcat([
    @variable(BnB_PEP_model, [1:dim_ğ±, 1:dim_ğ±], Symmetric, base_name = "Î˜[$i_j_Î»]")
    for i_j_Î» in idx_set_Î»]...), dim_ğ±, dim_ğ±, length(idx_set_Î»))

    # i.e, internally it will be defined as
    #     Î˜[:,:,k] (julia) = Î˜[i,j] (math) such that idx_set_Î»[k] = (i,j)
    # so in Julia, we for warm-start define these variables as follows
    # i_j_Î» = idx_set_Î»[â„“]
    # Î˜_ws[:,:,â„“] = âŠ™(ğ±_ws[:,i_j_Î».i]-ğ±_ws[:,i_j_Î».j], ğ±_ws[:,i_j_Î».i]-ğ±_ws[:,i_j_Î».j])
    # and similarly for the main variables


    # define the stepsize matrix Î±
    # ----------------------------
    if positive_step_size == :off
        @variable(BnB_PEP_model,  Î±[i = 1:N, j= 0:i-1])
    elseif positive_step_size == :on
        @variable(BnB_PEP_model, Î±[i = 1:N, j= 0:i-1] >= 0)
    end

    # [ğŸ‘² ] insert warm-start values for all the variables
    # ----------------------------------------------------

    @info "[ğŸ‘² ] warm-start values for all the variables"

    # warm start for Î», Ï„, Î·
    # ----------------------
    if reduce_index_set_for_dual_variables == :for_warm_start_only
        # warm start for Î»
        for i_j_Î» in idx_set_Î»_ws
            set_start_value(Î»[i_j_Î»], Î»_ws[i_j_Î»])
        end
        for i_j_Î» in setdiff(idx_set_Î», idx_set_Î»_ws)
            set_start_value(Î»[i_j_Î»], 0.0)
        end
        # warm start for Ï„
        for i_j_Ï„ in idx_set_Ï„_ws
            set_start_value(Ï„[i_j_Ï„], Ï„_ws[i_j_Ï„])
        end
        for i_j_Ï„ in setdiff(idx_set_Ï„, idx_set_Ï„_ws)
            set_start_value(Ï„[i_j_Ï„], 0.0)
        end
        # warm start for Î·
        for i_j_Î· in idx_set_Î·_ws
            set_start_value(Î·[i_j_Î·], Î·_ws[i_j_Î·])
        end
        for i_j_Î· in setdiff(idx_set_Î·, idx_set_Î·_ws)
            set_start_value(Î·[i_j_Î·], 0.0)
        end
    else
        # warm start for Î»
        for i_j_Î» in idx_set_Î»
            set_start_value(Î»[i_j_Î»], Î»_ws[i_j_Î»])
        end
        # warm start for Ï„
        for i_j_Ï„ in idx_set_Ï„
            set_start_value(Ï„[i_j_Ï„], Ï„_ws[i_j_Ï„])
        end
        # warm start for Î·
        for i_j_Î· in idx_set_Î·
            set_start_value(Î·[i_j_Î·], Î·_ws[i_j_Î·])
        end
    end

    # warm start for Î½
    # ----------------

    set_start_value(Î½, Î½_ws)

    # warm start for Z
    # ----------------

    for i in 1:dim_Z
        for j in 1:dim_Z
            set_start_value(Z[i,j], Z_ws[i,j])
        end
    end

    # warm start for L_cholesky
    # ------------------------

    if find_global_lower_bound_via_cholesky_lazy_constraint == :off
        for i in 1:dim_Z
            for j in 1:dim_Z
                set_start_value(L_cholesky[i,j], L_cholesky_ws[i,j])
            end
        end
    end

    # warm start for Î˜
    # ----------------

    # construct ğ±_ws, ğ _ws, ğŸ_ws corresponding to Î±_ws
    ğ±_ws, ğ _ws, ğŸ_ws = data_generator_function(N, Î±_ws, L; input_type = :stepsize_constant)

    # construct Î˜_ws step by step
    Î˜_ws = zeros(dim_ğ±, dim_ğ±, length(idx_set_Î»))

    for â„“ in 1:length(idx_set_Î»)
        i_j_Î» = idx_set_Î»[â„“]
        Î˜_ws[:,:,â„“] = âŠ™(ğ±_ws[:,i_j_Î».i]-ğ±_ws[:,i_j_Î».j], ğ±_ws[:,i_j_Î».i]-ğ±_ws[:,i_j_Î».j])
    end


    # setting the warm-start value for Î˜_ws

    for â„“ in 1:length(idx_set_Î»)
        i_j_Î» = idx_set_Î»[â„“]
        set_start_value.(Î˜[:,:,â„“], Î˜_ws[:,:,â„“])
    end


    # compute M_Î˜

    M_Î˜ = M_Î˜_factor*max(1,maximum(abs.(Î˜_ws)))

    # warm start for Î±
    # ----------------

    for i in 1:N
        for j in 0:i-1
            set_start_value(Î±[i,j], Î±_ws[i,j])
        end
    end

    # ************
    # [ğŸ‡ ] add objective
    # -------------
    # *************

    @info "[ğŸ‡ ] adding objective"

    @objective(BnB_PEP_model, Min, Î½*R^2)

    # Adding an upper bound for the objective function

    @constraint(BnB_PEP_model,  Î½*R^2 <= 1.001*d_star_ws) # this 1.001 factor gives some slack

    # Adding a lower bound for the objective function (if given)
    if global_lower_bound_given == :on
        @constraint(BnB_PEP_model,  Î½*R^2 >= global_lower_bound)
    end

    # ******************************
    # [ğŸ ] add the data generator function
    # *******************************

    @info "[ğŸ ] adding the data generator function to create ğ±, ğ , ğŸ"



    ğ±, ğ , ğŸ = data_generator_function(N, Î±, L; input_type = :stepsize_variable)

    # *******************
    # add the constraints
    # *******************


    # add the linear constraint
    # -------------------------


    @info "[ğŸ‹ ] adding linear constraint"

    @constraint(BnB_PEP_model,
    ( sum(Î»[i_j_Î»] * a_vec(i_j_Î».i, i_j_Î».j, ğŸ) for i_j_Î» in idx_set_Î») +
    sum(Ï„[i_Ï„] * a_vec(i_Ï„.i,-1,ğŸ) for i_Ï„ in idx_set_Ï„) +
    Î½*a_vec(-1,0,ğŸ)
    )
    .== 0
    )

    # add the constraint related to Î˜
    # -------------------------------

    # add the constraints corresponding to Î˜: (âˆ€(i,j) âˆˆ idx_set_Î») Î˜[:,:,position_of_(i,j)_in_idx_set_Î»] ==  âŠ™(ğ±[:,i] -ğ±[:,j], ğ±[:,i] - ğ±[:,j])
    # -----------------------------------------------------

    for â„“ in 1:length(idx_set_Î»)
        i_j_Î» = idx_set_Î»[â„“]
        @constraint(BnB_PEP_model, vectorize(
        Î˜[:,:,â„“] - âŠ™(ğ±[:,i_j_Î».i]-ğ±[:,i_j_Î».j], ğ±[:,i_j_Î».i]-ğ±[:,i_j_Î».j]),
        SymmetricMatrixShape(dim_ğ±)) .== 0)
    end

    # Okay, now let us add the LMI constraint:

    # modeling of the LMI constraint through vectorization (works same)
    # ------------------------------------
    # we are constructing term_1 + term_2 + term_3 + term_4 - term_5 == 0

    @info "[ğŸ¢ ] adding LMI constraint"

    if quadratic_equality_modeling == :exact

        # # direct modeling of the LMI constraint
        # ---------------------------------------

        @constraint(BnB_PEP_model,
        vectorize(
        # term 1: âˆ‘ Î·[i] C[i,â‹†] for iâˆˆ[0:N]
        ( -sum(Î·[i_Î·]*C_mat(i_Î·.i,-1,ğ ) for i_Î· in idx_set_Î·) ) +
        # term 2: (1/2L)*âˆ‘ Ï„[i] C[i,â‹†] for iâˆˆI_N_star
        ( (1/(2*L))*sum(Ï„[i_Ï„]*C_mat(i_Ï„.i,-1,ğ ) for i_Ï„ in idx_set_Ï„) ) +
        # term 3: âˆ‘ Î»[i,j]*( {0.5* ÌƒA [i,j]} + {(1/4L) * C[i,j] }) for i,j âˆˆ I_N_star
        (
        sum(Î»[i_j_Î»]*(
        ( (0.5)*A_tilde_mat(i_j_Î».i, i_j_Î».j, Î±, ğ , ğ±) ) +
        ( (1/(4*L))*C_mat(i_j_Î».i,i_j_Î».j,ğ ) )
        ) for i_j_Î» in idx_set_Î»)
        ) +
        # term 4: (-L/4) * âˆ‘ Î»[i,j] Î˜[:,:,position_of_(i,j)_in_idx_set_Î»]
        ( (-L/4)*sum( Î»[idx_set_Î»[â„“]]*Î˜[:,:,â„“] for â„“ in 1:length(idx_set_Î»)) ) -
        # term 5: Z
        Z,
        SymmetricMatrixShape(dim_Z)
        ) .== 0
        )

    elseif quadratic_equality_modeling == :through_Ïµ

        # modeling of the LMI constraint through vectorization and Ïµ_tol_feas
        # ---------------------------------------

        # part 1: models
        # (dual related terms) - Z <= Ïµ_tol_feas*ones(dim_Z,dim_z)
        @constraint(BnB_PEP_model,
        vectorize(
        # term 1: âˆ‘ Î·[i] C[i,â‹†] for iâˆˆ[0:N]
        ( -sum(Î·[i_Î·]*C_mat(i_Î·.i,-1,ğ ) for i_Î· in idx_set_Î·) ) +
        # term 2: (1/2L)*âˆ‘ Ï„[i] C[i,â‹†] for iâˆˆI_N_star
        ( (1/(2*L))*sum(Ï„[i_Ï„]*C_mat(i_Ï„.i,-1,ğ ) for i_Ï„ in idx_set_Ï„) ) +
        # term 3: âˆ‘ Î»[i,j]*( {0.5* ÌƒA [i,j]} + {(1/4L) * C[i,j] }) for i,j âˆˆ I_N_star
        (
        sum(Î»[i_j_Î»]*(
        ( (0.5)*A_tilde_mat(i_j_Î».i, i_j_Î».j, Î±, ğ , ğ±) ) +
        ( (1/(4*L))*C_mat(i_j_Î».i,i_j_Î».j,ğ ) )
        ) for i_j_Î» in idx_set_Î»)
        ) +
        # term 4: (-L/4) * âˆ‘ Î»[i,j] Î˜[:,:,position_of_(i,j)_in_idx_set_Î»]
        ( (-L/4)*sum( Î»[idx_set_Î»[â„“]]*Î˜[:,:,â„“] for â„“ in 1:length(idx_set_Î»)) ) -
        # term 5: Z
        Z - Ïµ_tol_feas*ones(dim_Z,dim_Z),
        SymmetricMatrixShape(dim_Z)
        ) .<= 0
        )

        # part 2: models
        # (dual related terms) - Z >= -Ïµ_tol_feas*ones(dim_Z,dim_z)
        @constraint(BnB_PEP_model,
        vectorize(
        # term 1: âˆ‘ Î·[i] C[i,â‹†] for iâˆˆ[0:N]
        ( -sum(Î·[i_Î·]*C_mat(i_Î·.i,-1,ğ ) for i_Î· in idx_set_Î·) ) +
        # term 2: (1/2L)*âˆ‘ Ï„[i] C[i,â‹†] for iâˆˆI_N_star
        ( (1/(2*L))*sum(Ï„[i_Ï„]*C_mat(i_Ï„.i,-1,ğ ) for i_Ï„ in idx_set_Ï„) ) +
        # term 3: âˆ‘ Î»[i,j]*( {0.5* ÌƒA [i,j]} + {(1/4L) * C[i,j] }) for i,j âˆˆ I_N_star
        (
        sum(Î»[i_j_Î»]*(
        ( (0.5)*A_tilde_mat(i_j_Î».i, i_j_Î».j, Î±, ğ , ğ±) ) +
        ( (1/(4*L))*C_mat(i_j_Î».i,i_j_Î».j,ğ ) )
        ) for i_j_Î» in idx_set_Î»)
        ) +
        # term 4: (-L/4) * âˆ‘ Î»[i,j] Î˜[:,:,position_of_(i,j)_in_idx_set_Î»]
        ( (-L/4)*sum( Î»[idx_set_Î»[â„“]]*Î˜[:,:,â„“] for â„“ in 1:length(idx_set_Î»)) ) -
        # term 5: Z
        Z + Ïµ_tol_feas*ones(dim_Z,dim_Z),
        SymmetricMatrixShape(dim_Z)
        ) .>= 0
        )

    else

        @error "something is not right in LMI modeling"

        return

    end


    # add sum(Î·) == 1 constraint
    # --------------------------

    @constraint(BnB_PEP_model, sum(Î·[i_Î·] for i_Î· in idx_set_Î·) .== 1)



    # add valid constraints for Z âª° 0
    # -------------------------------

    @info "[ğŸ© ] adding valid constraints for Z"

    # diagonal components of Z are non-negative
    for i in 1:dim_Z
        @constraint(BnB_PEP_model, Z[i,i] >= 0)
    end

    # the off-diagonal components satisfy:
    # (âˆ€i,j âˆˆ dim_Z: i != j) -(0.5*(Z[i,i] + Z[j,j])) <= Z[i,j] <=  (0.5*(Z[i,i] + Z[j,j]))

    for i in 1:dim_Z
        for j in 1:dim_Z
            if i != j
                @constraint(BnB_PEP_model, Z[i,j] <= (0.5*(Z[i,i] + Z[j,j])) )
                @constraint(BnB_PEP_model, -(0.5*(Z[i,i] + Z[j,j])) <= Z[i,j] )
            end
        end
    end

    # add cholesky related constraints
    # --------------------------------

    if find_global_lower_bound_via_cholesky_lazy_constraint == :off

        @info "[ğŸ­ ] adding cholesky matrix related constraints"

        # Two constraints to define the matrix L_cholesky to be a lower triangular matrix
        # -------------------------------------------------

        # upper off-diagonal terms of L_cholesky are zero

        for i in 1:dim_Z
            for j in 1:dim_Z
                if i < j
                    # @constraint(BnB_PEP_model, L_cholesky[i,j] .== 0)
                    fix(L_cholesky[i,j], 0; force = true)
                end
            end
        end

        # diagonal components of L_cholesky are non-negative

        for i in 1:dim_Z
            @constraint(BnB_PEP_model, L_cholesky[i,i] >= 0)
        end

    end

    # time to implement Z = L*L^T constraint
    # --------------------------------------

    if cholesky_modeling == :definition && find_global_lower_bound_via_cholesky_lazy_constraint == :off

        if quadratic_equality_modeling == :exact

            # direct modeling through definition and vectorization
            # ---------------------------------------------------
            @constraint(BnB_PEP_model, vectorize(Z - (L_cholesky * L_cholesky'), SymmetricMatrixShape(dim_Z)) .== 0)

        elseif quadratic_equality_modeling == :through_Ïµ

            # definition modeling through vectorization and Ïµ_tol_feas

            # part 1: models Z-L_cholesky*L_cholesky <= Ïµ_tol_feas*ones(dim_Z,dim_Z)
            @constraint(BnB_PEP_model, vectorize(Z - (L_cholesky * L_cholesky') - Ïµ_tol_feas*ones(dim_Z,dim_Z), SymmetricMatrixShape(dim_Z)) .<= 0)

            # part 2: models Z-L_cholesky*L_cholesky >= -Ïµ_tol_feas*ones(dim_Z,dim_Z)

            @constraint(BnB_PEP_model, vectorize(Z - (L_cholesky * L_cholesky') + Ïµ_tol_feas*ones(dim_Z,dim_Z), SymmetricMatrixShape(dim_Z)) .>= 0)

        else

            @error "something is not right in Cholesky modeling"

            return

        end


    elseif cholesky_modeling == :formula && find_global_lower_bound_via_cholesky_lazy_constraint == :off

        # Cholesky constraint 1
        # (âˆ€ j âˆˆ dim_Z) L_cholesky[j,j]^2 + âˆ‘_{kâˆˆ[1:j-1]} L_cholesky[j,k]^2 == Z[j,j]

        for j in 1:dim_Z
            if j == 1
                @constraint(BnB_PEP_model, L_cholesky[j,j]^2 == Z[j,j])
            elseif j > 1
                @constraint(BnB_PEP_model, L_cholesky[j,j]^2+sum(L_cholesky[j,k]^2 for k in 1:j-1) == Z[j,j])
            end
        end

        # Cholesky constraint 2
        # (âˆ€ i,j âˆˆ dim_Z: i > j) L_cholesky[i,j] L_cholesky[j,j] + âˆ‘_{kâˆˆ[1:j-1]} L_cholesky[i,k] L_cholesky[j,k] == Z[i,j]

        for i in 1:dim_Z
            for j in 1:dim_Z
                if i>j
                    if j == 1
                        @constraint(BnB_PEP_model, L_cholesky[i,j]*L_cholesky[j,j]  == Z[i,j])
                    elseif j > 1
                        @constraint(BnB_PEP_model, L_cholesky[i,j]*L_cholesky[j,j] + sum(L_cholesky[i,k]*L_cholesky[j,k] for k in 1:j-1) == Z[i,j])
                    end
                end
            end
        end

    elseif find_global_lower_bound_via_cholesky_lazy_constraint == :on

        # set_optimizer_attribute(BnB_PEP_model, "FuncPieces", -2) # FuncPieces = -2: Bounds the relative error of the approximation; the error bound is provided in the FuncPieceError attribute. See https://www.gurobi.com/documentation/9.1/refman/funcpieces.html#attr:FuncPieces

        # set_optimizer_attribute(BnB_PEP_model, "FuncPieceError", 0.1) # relative error

        set_optimizer_attribute(BnB_PEP_model, "MIPFocus", 1) # focus on finding good quality feasible solution

        # add initial cuts
        num_cutting_planes_init = 2*dim_Z^2
        cutting_plane_array = randn(dim_Z,num_cutting_planes_init)
        num_cuts_array_rows, num_cuts = size(cutting_plane_array)
        for i in 1:num_cuts
            d_cut = cutting_plane_array[:,i]
            d_cut = d_cut/norm(d_cut,2) # normalize the cutting plane vector
            @constraint(BnB_PEP_model, tr(Z*(d_cut*d_cut')) >= 0)
        end

        cutCount=0
        # maxCutCount=1e3

        # add the lazy callback function
        # ------------------------------
        function add_lazy_callback(cb_data)
            if cutCount<=maxCutCount
                Z0 = zeros(dim_Z,dim_Z)
                for i=1:dim_Z
                    for j=1:dim_Z
                        Z0[i,j]=callback_value(cb_data, Z[i,j])
                    end
                end
                if eigvals(Z0)[1]<=-0.01
                    u_t = eigvecs(Z0)[:,1]
                    u_t = u_t/norm(u_t,2)
                    con3 = @build_constraint(tr(Z*u_t*u_t') >=0.0)
                    MOI.submit(BnB_PEP_model, MOI.LazyConstraint(cb_data), con3)
                    # noPSDCuts+=1
                end
                cutCount+=1
            end
        end

        # submit the lazy constraint
        # --------------------------
        MOI.set(BnB_PEP_model, MOI.LazyConstraintCallback(), add_lazy_callback)


    end

    # impose bound on the variables if bound_impose == :on

    if bound_impose == :on
        @info "[ğŸŒƒ ] finding bound on the variables"

        # store the values

        Î»_lb = 0
        Î»_ub = M_Î»
        Ï„_lb = 0
        Ï„_ub = M_Ï„
        Î·_lb = 0
        Î·_ub = M_Î·
        Î½_lb = 0
        Î½_ub = Î½_ws
        Z_lb = -M_Z
        Z_ub = M_Z
        L_cholesky_lb = -M_L_cholesky
        L_cholesky_ub = M_L_cholesky
        Î±_lb = -M_Î±
        Î±_ub = M_Î±
        Î˜_lb = -M_Î˜
        Î˜_ub = M_Î˜

        # set bound for Î»
        # ---------------
        # set_lower_bound.(Î», Î»_lb): done in definition
        set_upper_bound.(Î», Î»_ub)

        # set bound for Ï„
        # set_lower_bound.(Ï„, Ï„_lb): done in definition
        set_upper_bound.(Ï„, Ï„_ub)

        # set bound for Î·
        #  set_lower_bound.(Î·, Î·_lb): done in definition
        set_upper_bound.(Î·, Î·_ub)

        # set bound for Î½
        # ---------------
        # set_lower_bound.(Î½, Î½_lb): done in definition
        set_upper_bound(Î½, Î½_ub)

        # set bound for Z
        # ---------------
        for i in 1:dim_Z
            for j in 1:dim_Z
                set_lower_bound(Z[i,j], Z_lb)
                set_upper_bound(Z[i,j], Z_ub)
            end
        end

        # set bound for L_cholesky
        # ------------------------

        if find_global_lower_bound_via_cholesky_lazy_constraint == :off
            # need only upper bound for the diagonal compoments, as the lower bound is zero from the model
            for i in 1:N+2
                set_upper_bound(L_cholesky[i,i], L_cholesky_ub)
            end
            # need to bound only components, L_cholesky[i,j] with i > j, as for i < j, we have zero, due to the lower triangular structure
            for i in 1:N+2
                for j in 1:N+2
                    if i > j
                        set_lower_bound(L_cholesky[i,j], L_cholesky_lb)
                        set_upper_bound(L_cholesky[i,j], L_cholesky_ub)
                    end
                end
            end
        end

        # set bound for Î˜
        # ---------------
        set_lower_bound.(Î˜, Î˜_lb)
        set_upper_bound.(Î˜, Î˜_ub)

        # set bound for Î±
        # ---------------
        set_lower_bound.(Î±, Î±_lb)
        set_upper_bound.(Î±, Î±_ub)

    end

    # impose the effective index set of L_cholesky if reduce_index_set_for_L_cholesky  == :on and we are not computing a global lower bound
    # ----------------------------------------------

    if find_global_lower_bound_via_cholesky_lazy_constraint == :off && reduce_index_set_for_L_cholesky == :on
        zis_Lc = zero_index_set_finder_L_cholesky(L_cholesky_ws; Ïµ_tol = Ïµ_tol_Cholesky)
        for k in 1:length(zis_Lc)
            fix(L_cholesky[CartesianIndex(zis_Lc[k])], 0; force = true)
        end
    end

    # impose pattern found by solving smaller values of N
    # ---------------------------------------------------

    if impose_pattern == :on

        @info "[ğŸŠ ] imposing pattern"

        # set L_cholesky = 0

        if find_global_lower_bound_via_cholesky_lazy_constraint == :off

            for i in 1:dim_Z
                for j in 1:dim_Z
                    fix(L_cholesky[i, j], 0.0; force = true)
                end
            end

        end

        # set Z = 0

        for i in 1:dim_Z
            for j in 1:dim_Z
                fix(Z[i, j], 0.0; force = true)
            end
        end

        # set Ï„[0]=Ï„[1]=â€¦=Ï„[N-1]=0

        idx_set_zero_Î», idx_set_zero_Ï„, idx_set_zero_Î· = index_set_zero_entries_dual_variables(N, idx_set_Î», idx_set_Ï„, idx_set_Î·)

        for i_Ï„ in idx_set_zero_Ï„
            fix(Ï„[i_Ï„], 0.0; force = true)
        end

        for i_j_Î» in idx_set_zero_Î»
            fix(Î»[i_j_Î»], 0.0; force = true)
        end

    end

    # Time to optimize and store


    # time to optimize
    # ----------------

    @info "[ğŸ™Œ 	ğŸ™ ] model building done, starting the optimization process"

    if show_output == :off
        set_silent(BnB_PEP_model)
    end

    optimize!(BnB_PEP_model)

    @info "BnB_PEP_model has termination status = " termination_status(BnB_PEP_model)

    if (solution_type == :find_locally_optimal && termination_status(BnB_PEP_model) == MOI.LOCALLY_SOLVED) || (solution_type ==:find_globally_optimal && termination_status(BnB_PEP_model) == MOI.OPTIMAL )

        # store the solutions and return
        # ------------------------------

        @info "[ğŸ˜» ] optimal solution found done, store the solution"

        # store Î»_opt

        Î»_opt = value.(Î»)

        # store Ï„_opt

        Ï„_opt = value.(Ï„)

        # store Î·_opt

        Î·_opt = value.(Î·)

        # store Î½_opt

        Î½_opt = value.(Î½)

        # store Î±_opt

        Î±_opt = value.(Î±)

        # store Î˜_opt

        Î˜_opt = value.(Î˜)

        # store Z_opt

        Z_opt = value.(Z)

        # store L_cholesky

        if find_global_lower_bound_via_cholesky_lazy_constraint == :off

            L_cholesky_opt = value.(L_cholesky)

            if norm(Z_opt - L_cholesky_opt*L_cholesky_opt', Inf) > 10^-4
                @warn "||Z - L_cholesky*L_cholesky^T|| = $(norm(Z_opt -  L_cholesky_opt*L_cholesky_opt', Inf))"
            end

        elseif find_global_lower_bound_via_cholesky_lazy_constraint == :on

            L_cholesky_opt = compute_pivoted_cholesky_L_mat(Z_opt)

            # in this case doing the cholesky check does not make sense, because we are not aiming to find a psd Z_opt

            # if norm(Z_opt - L_cholesky_opt*L_cholesky_opt', Inf) > 10^-4
            #     @info "checking the norm bound"
            #     @warn "||Z - L*L^T|| = $(norm(Z_opt - L_cholesky_opt*L_cholesky_opt', Inf))"
            # end

        end

        obj_val = objective_value(BnB_PEP_model)

    else

        @warn "[ğŸ™€ ] could not find an optimal solution, returning the warm-start point"

        obj_val, Î»_opt, Ï„_opt, Î·_opt, Î½_opt, Z_opt, L_cholesky_opt, Î˜_opt, Î±_opt, idx_set_Î»_opt_effective, idx_set_Ï„_opt_effective, idx_set_Î·_opt_effective = d_star_ws, Î»_ws, Ï„_ws, Î·_ws, Î½_ws, Z_ws, L_cholesky_ws, Î˜_ws, Î±_ws, idx_set_Î»_ws_effective, idx_set_Ï„_ws_effective, idx_set_Î·_ws_effective

    end


    if polish_solution == :on && find_global_lower_bound_via_cholesky_lazy_constraint == :off # note that if we are finding a global lower bound, then polishing the solution would not make sense

        @info "[ğŸ£ ] polishing and sparsifying the solution"


        obj_val, â„“_1_norm_Î»_dummy, â„“_1_norm_Ï„_dummy, â„“_1_norm_Î·_dummy, tr_Z_dummy, Î»_opt, Ï„_opt, Î·_opt, Î½_opt, Z_opt, L_cholesky_opt, Î˜_opt, Î±_opt, idx_set_Î»_effective_dummy, idx_set_Ï„_effective_dummy, idx_set_Î·_effective_dummy = solve_dual_PEP_with_known_stepsizes(N, R, L, Î±_opt;  show_output = :off,
        Ïµ_tol_feas = 1e-6, objective_type = :default, obj_val_upper_bound = 1.0001*obj_val)

        obj_val_sparse, â„“_1_norm_Î»_dummy, â„“_1_norm_Ï„_dummy, â„“_1_norm_Î·_dummy, tr_Z_dummy, Î»_opt, Ï„_opt, Î·_opt, Î½_opt, Z_opt, L_cholesky_opt, Î˜_opt, Î±_opt, idx_set_Î»_effective_dummy, idx_set_Ï„_effective_dummy, idx_set_Î·_effective_dummy = solve_dual_PEP_with_known_stepsizes(N, R, L, Î±_opt;  show_output = :off,
        Ïµ_tol_feas = 1e-6, objective_type = :find_sparse_sol, obj_val_upper_bound = (1+(1e-6))*obj_val)

    end

    # find the effective index set of the found Î», Ï„, Î·

    idx_set_Î»_opt_effective, idx_set_Ï„_opt_effective, idx_set_Î·_opt_effective = effective_index_set_finder(Î»_opt, Ï„_opt, Î·_opt; Ïµ_tol = 0.0005)

    @info "[ğŸš§ ] for Î», only $(length(idx_set_Î»_opt_effective)) components out of $(length(idx_set_Î»)) are non-zero for the optimal solution"

    @info "[ğŸš§ ] for Ï„, only $(length(idx_set_Ï„_opt_effective)) components out of $(length(idx_set_Ï„)) are non-zero for the optimal solution"

    @info "[ğŸš§ ] for Î·, only $(length(idx_set_Î·_opt_effective)) components out of $(length(idx_set_Î·)) are non-zero for the optimal solution"

    @info "[ğŸ’¹ ] warm-start objective value = $d_star_ws, and objective value of found solution = $obj_val"

    # verify if any of the imposed bounds are violated

    if bound_impose == :on && find_global_lower_bound_via_cholesky_lazy_constraint == :off
        bound_satisfaction_flag = bound_violation_checker_BnB_PEP(obj_val, Î»_opt, Ï„_opt, Î·_opt, Î½_opt, Z_opt, L_cholesky_opt, Î˜_opt, Î±_opt,
        Î»_lb, Î»_ub, Ï„_lb, Ï„_ub, Î·_lb, Î·_ub, Î½_lb, Î½_ub, Z_lb, Z_ub, L_cholesky_lb, L_cholesky_ub, Î˜_lb, Î˜_ub, Î±_lb, Î±_ub;
        show_output = :on,
        computing_global_lower_bound = :off)
    elseif bound_impose == :on && find_global_lower_bound_via_cholesky_lazy_constraint == :on
        bound_satisfaction_flag = bound_violation_checker_BnB_PEP(obj_val, Î»_opt, Ï„_opt, Î·_opt, Î½_opt, Z_opt, L_cholesky_opt, Î˜_opt, Î±_opt,
        Î»_lb, Î»_ub, Ï„_lb, Ï„_ub, Î·_lb, Î·_ub, Î½_lb, Î½_ub, Z_lb, Z_ub, L_cholesky_lb, L_cholesky_ub, Î˜_lb, Î˜_ub, Î±_lb, Î±_ub;
        show_output = :on,
        computing_global_lower_bound = :on)
    end

    # time to return all the stored values

    return obj_val, Î»_opt, Ï„_opt, Î·_opt, Î½_opt, Z_opt, L_cholesky_opt, Î˜_opt, Î±_opt, idx_set_Î»_opt_effective, idx_set_Ï„_opt_effective, idx_set_Î·_opt_effective

end

